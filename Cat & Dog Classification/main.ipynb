{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------LOADING IN OUR OWN TRAINING & TESTING DATASET--------------------------\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "TRAIN_DATA_DIR = \"cats_and_dogs_filtered\\\\train\"\n",
    "TEST_DATA_DIR = \"cats_and_dogs_filtered\\\\validation\"\n",
    "CLASSES = [\"dogs\", \"cats\"]\n",
    "\n",
    "training_data = []\n",
    "testing_data = []\n",
    "\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "\n",
    "def create_training_data():\n",
    "    for the_class in CLASSES:\n",
    "        path = os.path.join(TRAIN_DATA_DIR, the_class)   # Path to cats or dogs directory\n",
    "        class_num = CLASSES.index(the_class)   #Giving labels to each image. 0 for Dog and 1 for Cat.\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img))  # We're converting read images into grayscale image since color is not essential for this classification task\n",
    "                new_array = cv2.resize(img_array, (IMG_WIDTH, IMG_HEIGHT))  #Normalizing or Resizing the dataset so that each image is of same size\n",
    "                training_data.append([new_array, class_num])\n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "def create_testing_data():\n",
    "    for the_class in CLASSES:\n",
    "        path = os.path.join(TEST_DATA_DIR, the_class)   # Path to cats or dogs directory\n",
    "        class_num = CLASSES.index(the_class)   #Giving labels to each image. 0 for Dog and 1 for Cat.\n",
    "        for img in os.listdir(path):\n",
    "            img_array = cv2.imread(os.path.join(path,img))  # We're converting read images into grayscale image since color is not essential for this classification task\n",
    "            new_array = cv2.resize(img_array, (IMG_WIDTH, IMG_HEIGHT))  #Normalizing or Resizing the dataset so that each image is of same size\n",
    "            testing_data.append([new_array, class_num]) \n",
    "\n",
    "\n",
    "create_training_data()\n",
    "create_testing_data()\n",
    "\n",
    "print(\"Total Training Images: \"+str(len(training_data)))\n",
    "print(\"Total Testing Images: \"+str(len(testing_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------RESHAPING THE TRAINING DATASET--------------------------\n",
    "X_train = []   #Will contain training images\n",
    "Y_train = []   #Will contain labels for training images\n",
    "\n",
    "X_test = []   #Will contain testing images\n",
    "Y_test = []  #Will contain labels for testing images\n",
    "\n",
    "for image, label in training_data:\n",
    "    X_train.append(image)\n",
    "    Y_train.append(label)\n",
    "\n",
    "for image, label in testing_data:\n",
    "    X_test.append(image)\n",
    "    Y_test.append(label)\n",
    "    \n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "X_train = np.array(X_train).reshape(X_train.shape[0], IMG_WIDTH, IMG_HEIGHT, 3)                                                                #-1 tells us the number of features/image. Then we have the size of image i.e width and height and last 1 tells us that the image is gray scale\n",
    "X_test = np.array(X_test).reshape(X_test.shape[0], IMG_WIDTH, IMG_HEIGHT, 3)                                                                   #-1 tells us the number of features/image. Then we have the size of image i.e width and height and last 1 tells us that the image is gray scale\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "print(\"Reshaping completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------SAVING THE TRAINING & TESTING DATASET--------------------------\n",
    "#Saving the training features and labels\n",
    "np.save('train_features.npy', X_train) \n",
    "np.save('train_labels.npy',Y_train)\n",
    "print(\"Training data saved\")\n",
    "\n",
    "#Saving the testing features and labels\n",
    "np.save('test_features.npy', X_test) \n",
    "np.save('test_labels.npy',Y_test)\n",
    "print(\"Testing data saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------LOADING THE TRAINING & TESTING DATASET--------------------------\n",
    "#Loading training features and labels\n",
    "import numpy as np\n",
    "X_train=np.load('train_features.npy')\n",
    "Y_train=np.load('train_labels.npy')\n",
    "print(\"Training data loaded\")\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "#Loading testing features and labels\n",
    "X_test=np.load('test_features.npy')\n",
    "Y_test=np.load('test_labels.npy')\n",
    "print(\"Testing data loaded\")\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------DEFINING & SAVING OUR CNN MODEL---------------------------------------------------------\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "num_classes = 2\n",
    "batch_size = 128\n",
    "IMG_WIDTH = 150\n",
    "IMG_HEIGHT = 150\n",
    "epochs = 50\n",
    "\n",
    "\n",
    "# Normalizing the data\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "\n",
    "input_shape = (IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes) \n",
    "\n",
    "\n",
    "#Defining the structure of the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation='sigmoid'))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "          \n",
    "#Adding the parameters for the model\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#Training the model\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "#---------------------------------------------------SAVING THE MODEL---------------------------------------------------------\n",
    "model.save('catdog_classification-CNN.model')\n",
    "print(\"Model Saved: catdog_classification-CNN.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n",
      "Epoch 1/30\n",
      "100/100 [==============================] - 22s 218ms/step - loss: 0.7082 - acc: 0.4995 - val_loss: 0.6913 - val_acc: 0.6490\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 18s 178ms/step - loss: 0.6955 - acc: 0.5125 - val_loss: 0.6713 - val_acc: 0.5630\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 0.6887 - acc: 0.5675 - val_loss: 0.6983 - val_acc: 0.5110\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 0.6601 - acc: 0.6030 - val_loss: 0.6426 - val_acc: 0.6580\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 0.6598 - acc: 0.6210 - val_loss: 0.6002 - val_acc: 0.6850\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 0.6420 - acc: 0.6470 - val_loss: 0.6107 - val_acc: 0.6520\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 18s 177ms/step - loss: 0.6351 - acc: 0.6555 - val_loss: 0.5923 - val_acc: 0.6790\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 0.6192 - acc: 0.6590 - val_loss: 0.5938 - val_acc: 0.6860\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.6322 - acc: 0.6500 - val_loss: 0.5813 - val_acc: 0.6930\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 18s 177ms/step - loss: 0.6246 - acc: 0.6785 - val_loss: 0.5777 - val_acc: 0.6930\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 18s 182ms/step - loss: 0.6197 - acc: 0.6930 - val_loss: 0.5778 - val_acc: 0.6830\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.6018 - acc: 0.6680 - val_loss: 0.6297 - val_acc: 0.6310\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 0.6014 - acc: 0.6880 - val_loss: 0.5999 - val_acc: 0.6630\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.6027 - acc: 0.6785 - val_loss: 0.5552 - val_acc: 0.7180\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 0.5884 - acc: 0.7005 - val_loss: 0.5496 - val_acc: 0.7110\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 18s 175ms/step - loss: 0.5907 - acc: 0.7030 - val_loss: 0.5580 - val_acc: 0.7060\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 18s 177ms/step - loss: 0.5849 - acc: 0.7005 - val_loss: 0.5673 - val_acc: 0.7060\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 17s 174ms/step - loss: 0.5846 - acc: 0.6925 - val_loss: 0.5591 - val_acc: 0.7310\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 0.5918 - acc: 0.7015 - val_loss: 0.8632 - val_acc: 0.5980\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 0.5814 - acc: 0.6980 - val_loss: 0.5391 - val_acc: 0.7170\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 18s 177ms/step - loss: 0.5746 - acc: 0.7170 - val_loss: 0.5261 - val_acc: 0.7410\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.5756 - acc: 0.7205 - val_loss: 0.5198 - val_acc: 0.7340\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 0.5573 - acc: 0.7185 - val_loss: 0.5155 - val_acc: 0.7620\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 0.5669 - acc: 0.7190 - val_loss: 0.5270 - val_acc: 0.7470\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 18s 176ms/step - loss: 0.5419 - acc: 0.7325 - val_loss: 0.5352 - val_acc: 0.7380\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 0.5529 - acc: 0.7255 - val_loss: 0.4978 - val_acc: 0.7480\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 19s 191ms/step - loss: 0.5423 - acc: 0.7315 - val_loss: 0.5088 - val_acc: 0.7600\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 0.5551 - acc: 0.7260 - val_loss: 0.4998 - val_acc: 0.7350\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 0.5555 - acc: 0.7345 - val_loss: 0.4802 - val_acc: 0.7600\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 18s 183ms/step - loss: 0.5310 - acc: 0.7395 - val_loss: 0.4752 - val_acc: 0.7700\n",
      "Model Saved: New-catdog_classification-CNN.model\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------DATA AUGMENTATION AND THEN TRAINING---------------------------------------------------\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "TRAIN_DATA_DIR = \"cats_and_dogs_filtered\\\\train\"\n",
    "TEST_DATA_DIR = \"cats_and_dogs_filtered\\\\validation\"\n",
    "\n",
    "num_classes = 2\n",
    "batch_size = 128\n",
    "IMG_WIDTH = 150\n",
    "IMG_HEIGHT = 150\n",
    "epochs = 50\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "# Adding rescale, rotation_range, width_shift_range, height_shift_range,\n",
    "# shear_range, zoom_range, and horizontal flip to our ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        TRAIN_DATA_DIR,  # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 32 using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        TEST_DATA_DIR,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "\n",
    "\n",
    "# Our input feature map is 150x150x3: 150x150 for the image pixels, and 3 for\n",
    "# the three color channels: R, G, and B\n",
    "img_input = layers.Input(shape=(150, 150, 3))\n",
    "\n",
    "# First convolution extracts 16 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "x = layers.Conv2D(16, 3, activation='relu')(img_input)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "# Second convolution extracts 32 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "x = layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "# Third convolution extracts 64 filters that are 3x3\n",
    "# Convolution is followed by max-pooling layer with a 2x2 window\n",
    "x = layers.Convolution2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "x = layers.Convolution2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2)(x)\n",
    "\n",
    "# Flatten feature map to a 1-dim tensor\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# Create a fully connected layer with ReLU activation and 512 hidden units\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "\n",
    "# Create output layer with a single node and sigmoid activation\n",
    "output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Configure and compile the model\n",
    "model = Model(img_input, output)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.001),\n",
    "              metrics=['acc'])\n",
    "\n",
    "#history = model.fit_generator(\n",
    "#      train_generator,\n",
    "#      steps_per_epoch=100,\n",
    "#      epochs=30,\n",
    "#      validation_data=validation_generator,\n",
    "#      validation_steps=50,\n",
    "#      verbose=1)\n",
    "\n",
    "#Training the model\n",
    "model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      verbose=1)\n",
    "\n",
    "#---------------------------------------------------SAVING THE MODEL---------------------------------------------------------\n",
    "model.save('New-catdog_classification-CNN.model')\n",
    "print(\"Model Saved: New-catdog_classification-CNN.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------DEFINING & SAVING RESNET MODEL---------------------------------------------------------\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from resnets_utils import *\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)\n",
    "\n",
    "num_classes = 2\n",
    "batch_size = 128\n",
    "IMG_WIDTH = 50\n",
    "IMG_HEIGHT = 50\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "input_shape = (IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "\n",
    "\n",
    "def ResNet50(input_shape=input_shape, classes=num_classes):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "\n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Stage 3 (≈4 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    # Stage 4 (≈6 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    # Stage 5 (≈3 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model\n",
    "\n",
    "model = ResNet50(input_shape = input_shape, classes = num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "\n",
    "print (\"Number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"Number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------DEFINING & SAVING VGG MODEL---------------------------------------------------------\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "import cv2, numpy as np\n",
    "\n",
    "\n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "num_classes = 2\n",
    "batch_size = 28\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "# Normalizing the data\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "\n",
    "input_shape = (IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes) \n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "#Defining the structure of the model\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1,1),input_shape=input_shape))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))          \n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))          \n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))          \n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))          \n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))          \n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))          \n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))          \n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))          \n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))          \n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))          \n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))          \n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))          \n",
    "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "          \n",
    "#Adding the parameters for the model\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer='adam', loss=keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "#Training the model\n",
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "         validation_data=(X_test, Y_test))\n",
    "\n",
    "#---------------------------------------------------SAVING THE MODEL---------------------------------------------------------\n",
    "model.save('catdog_classification-VGG.model')\n",
    "print(\"Model Saved: catdog_classification-VGG.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------lOADING OUR CNN MODEL---------------------------------------------------------\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import keras\n",
    "from numpy import array\n",
    "\n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "loaded_model = keras.models.load_model('catdog_classification-CNN.model')\n",
    "print(\"Model loaded: catdog_classification-CNN.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------------lOADING VGG MODEL---------------------------------------------------------\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import keras\n",
    "from numpy import array\n",
    "\n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "loaded_model = keras.models.load_model('catdog_classification-VGG.model')\n",
    "print(\"Model loaded: catdog_classification-VGG.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------EVALUATING VALIDATION LOSS AND ACCURACY---------------------------------------------------------\n",
    "val_loss, val_acc = loaded_model.evaluate(X_test, Y_test)\n",
    "print(\"\\nValidation Loss: \"+str(val_loss*100)+\"%\")\n",
    "print(\"Validation Accuracy: \"+str(val_acc*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------PREDICTING OUTPUT OF GIVEN TEST IMAGES----------------------------------------------------\n",
    "image_dir = \"Test Images/\"\n",
    "test_images = []\n",
    "IMG_WIDTH = 50\n",
    "IMG_HEIGHT = 50\n",
    "for filename in glob.glob(image_dir+\"*.jpg\"): #Searching for png images in Test Images\n",
    "    img = cv2.imread(filename)\n",
    "    resized_image = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT)) \n",
    "    test_images.append(resized_image)\n",
    "\n",
    "test_images = array(test_images)   #Converting list to numpy array\n",
    "test_images = test_images/255.0\n",
    "test_images = test_images.reshape(test_images.shape[0], IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "predictions = loaded_model.predict([test_images])\n",
    "for i in range(len(test_images)):\n",
    "    plt.imshow(test_images[i])\n",
    "    plt.show()\n",
    "    if(np.argmax(predictions[i]) == 0):\n",
    "        print(\"Prediction: Dog\")\n",
    "    elif(np.argmax(predictions[i]) == 1):\n",
    "        print(\"Prediction: Cat\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "TRAIN_DATA_DIR = \"cats_and_dogs_filtered\\\\train\"\n",
    "TEST_DATA_DIR = \"cats_and_dogs_filtered\\\\validation\"\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "# Adding rescale, rotation_range, width_shift_range, height_shift_range,\n",
    "# shear_range, zoom_range, and horizontal flip to our ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        TRAIN_DATA_DIR,  # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 32 using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        TEST_DATA_DIR,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
